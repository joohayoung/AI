{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공지능 사관학교 1주차.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFjI/UEJIJF7LIzscdBiV4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joohayoung/AI/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EC%82%AC%EA%B4%80%ED%95%99%EA%B5%90_1%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-B1pPZ6qz_c",
        "colab_type": "text"
      },
      "source": [
        "# 인공지능 사관학교 1주차 과제\n",
        "\n",
        "**<언어, 음성, 이미지, 자율주행 분야의 인공지능 기술>**\n",
        "\n",
        "\n",
        "**1. 언어**\n",
        "\n",
        "![대체 텍스트](https://www.sciencetimes.co.kr/wp-content/uploads/2018/05/%EC%8B%AC%EC%8B%AC%EC%9D%B4.jpg)\n",
        "\n",
        "AI 챗봇 '심심이'\n",
        "‘심심이’는 이즈메이커가 개발한 온라인 인공지능 ‘챗봇(Chatbot)’이다. 병아리 모양으로 형상화 된 챗봇 ‘심심이’가 세상에 나온 지는 16년이나 됐다. 2002년 처음 마이크로소프트의 메신저 MSN에서 ‘MSN 심심이’로 만들어졌다가 지난 2010년 스마트폰 앱이 출시됐다. 시대에 맞게 심심이도 인공지능 딥러닝 학습을 통해 거듭났다. 패턴인식, 시멘틱 웹, 텍스트 마이닝, 상황인식컴퓨팅, 자연어 처리 능력을 갖췄다.\n",
        "\n",
        "‘심심이’ 어플은 지난 16년 동안 1억 개 앱이 다운로드 되었으며 서비스 되는 언어도 80여종에 이른다. 앱 스토어 1위 국가도 50여 국가나 된다. 하지만 주변에서 ‘심심이’를 쓴다는 사람을 찾기는 쉽지 않다. 국내 사용자보다는 해외 사용자가 많은 탓이다. 전체 심심이 사용자 중 대부분은 남아메리카 권역과 유럽 권역에 속한다.\n",
        "\n",
        "해외에서 인기를 얻고 있는 ‘심심이’가 큰 문제에 부딪치게 된 일은 지난해 영국과 아일랜드에서 일어난 ‘사이버블링(Cyberbullying)’을 통해서였다. ‘사이버블링’이란 사이버 폭력을 뜻한다. 사회관계망서비스(SNS) 등 온라인상에서의 모욕, 언어폭력 등이 ‘사이버블링’에 속한다.\n",
        "\n",
        "\n",
        "\n",
        "**2. 음성**\n",
        "\n",
        "\n",
        "미국최대 전자상거래업체인 아마존이 2014년 내놓은 음성인식 인공지능(AI)비서. 아마존에서 179달러짜리 원통형 스피커 ‘에코’를 사서 설치하면 목소리로 각종 가전기기나 난방, 조명 등을 작동할 수 있다. 자동차와 연계해 추운 날 집안에서 시동을 걸고 히터를 미리 켜둘 수도 있다. 궁금한 뉴스를 알려주거나 일상적인 팁을 제공하기도 한다.![대체 텍스트](https://techrecipe.co.kr/wp-content/uploads/2018/09/180924_Echo-Dot_001_.jpg)\n",
        "\n",
        "우리가 인공지능 기반 음성인식 제품에 말을 하면, **“음성 입력 및 인식 → 자연어 처리 → 인식 결과”**의 단계를 거친다. 기계가 사람의 언어를 인식하고 이해하기 위해 필요한 과정이다.\n",
        "\n",
        "첫 번째 과정에서는 음성 입력 과정을 거쳐 사람의 음성을 컴퓨터가 이해할 수 있도록 텍스트화한다. 이 기술을 STT(Speech To Text)라고 한다. 어린아이가 받아쓰기를 하듯이 사람의 음성을 텍스트로 옮기는 것이다. 주변 소음을 제외한 말소리를 파악하고 이어서 각 발음과 단어를 인식한 후 핵심어와 연결 단어를 인식해 입력해야 하므로 생각보다 간단하고 쉽지만은 않다.\n",
        "\n",
        "두 번째는 자연어 처리(Natural Language Processing, NLP) 과정이다. 자연어란 사람이 의사소통을 위해 사용하는 언어이다. 자연어 처리란 컴퓨터가 자연어를 분석하여 이해하고 처리하는 기술이다. 이 과정에서는 자연어에 대한 형태소 분석, 구문 해석, 의미 분석, 화용 분석 등을 통해 컴퓨터가 문장에 담긴 의도를 파악하게 다. 한이 자연어 처리는 인공지능의 주요 분야이다. 인공지능 기계가 사람의 언어를 얼마나 잘 파악하였는지를 알 수 있는 과정이다.\n",
        "\n",
        "앞선 과정을 거쳐 마지막으로 기계는 인식 결과를 내놓는다. 인식된 요청에 따라 가장 최적의 결과를 찾아내고, TTS(Text to Speech) 기술을 통해 사람의 말소리처럼 응답하는 것이다. 친구에게 메시지를 보내라고 말했다면 전달한 내용으로 메시지를 전송하고, 날씨를 물어봤다면 인터넷에서 위치 기반의 날씨를 검색해 대답해준다.\n",
        "간단하게 “지금 미국은 몇 시야?”라고 질문하고 답을 받았을 뿐인데, 사실은 기계는 굉장히 빠르게 우리의 말을 분석하고 이해해서 그에 맞는 반응을 보인 것이다.\n",
        "\n",
        "**3. 이미지**\n",
        "\n",
        "![대체 텍스트](https://img1.daumcdn.net/thumb/R720x0/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fliveboard%2Fbizion%2Ffb896e5f9fd24987ad9211954dbe0aa4.JPG)\n",
        "\n",
        "구글의 인공지능 부문(Google AI)은 샌디에고 해군 의료센터(Naval Medical Center San Diego)와 공동으로 유방암 림프절 전이를 자동 감지하는 새로운 암 탐지 알고리즘을 개발했다. LYNA라고 명명한 이 인공지능 시스템은 의학저널 ‘The American Journal of Surgical Pathology’의 논문을 통해 발표된 바 있다. 일반적으로 전이성 유방암은 의사들도 판별하기가 매우 어려운 암으로 정평이 나 있다. 2017년에 발표한 한 연구자료에 따르면 숙련된 의사도 제한된 시간과 제약 하에서 미세한 암 전이 중 62%를 놓칠 수 있다는 예측을 내놓기도 했다.\n",
        "\n",
        "LYNA는 병리학을 훈련할 때와 같은 프레임워크를 적용해 학습의 과정을 통해 탄생했다. 오픈소스 이미지 인식 딥러닝 모델인 ‘인셉션-v3(Inception-v3)’을 바탕으로 입력된 이미지에서 픽셀 수준까지 암을 찾아낼 수 있다. 연구팀은 LYNA를 학습시키는 과정에서 교육에 이용하는 조직 라벨을 양성과 종양 비율을 4:1로 적용해 학습 효율을 높이는 데 성공했다. 그 결과 LYNA는 전이성 유방암에 대한 영상진단 정확도 측정에서 무려 99.3%에 달하는 정확도를 달성했다. 물론 오인 사례도 있었지만 기포나 출혈, 염색 과다 등 결함에 영향을 받지 않고 인간보다 뛰어난 전이성 유방암 탐지 능력을 보여준 것은 틀림없는 사실이다.\n",
        "\n",
        "LYNA는 병리학보다 높은 전이성 유방암 탐지 능력을 갖췄으며, 병리학 진단 지원을 통해 진단 과정의 효율성 향상은 물론 오류 감소에도 도움을 줄 수 있을 것으로 예상된다.\n",
        "\n",
        "\n",
        "**4. 자율주행**\n",
        "\n",
        "![대체 텍스트](https://techrecipe.co.kr/wp-content/uploads/2019/04/190423_Tesla_901.jpg)\n",
        "\n",
        "자율주행 자동차 '테슬라'\n",
        "자율주행 기술의 핵심은 자동차가 주변 상황을 탐지하고 이를 빠르게 분석해 운행에 반영하는 일이다. 하지만 단순히 차량 내 센서를 활용하는 과정에는 한계가 있다. 운행 과정에 변수가 많기 때문이다. 차량의 움직임은 어느 정도 예상할 수 있겠지만 주변에서 갑자가 다가오는 동물이나 사람, 자연에 의한 갑작스런 환경 변화 등에는 쉽게 대응하기 어렵다.\n",
        "\n",
        "5G 서비스는 단순히 빠른 인터넷 속도뿐만 아니라 이를 기반으로 사회 다양한 인프라 및 서비스 질을 높일 수 있다.\n",
        "이 때 필요한 것은 초고속 이동 통신, 주변에서 벌어지는 상황을 빠르게 전송하고 주행에 반영하는 것으로 자율주행의 변수를 어느 정도 해결할 수 있다. 하지만 단순히 통신만으로 해결되는 문제는 아니다. 데이터가 방대하고 빠르게 송수신이 이뤄져야 한다. 자율주행차 기술이 5G 이동통신과 관련 제품들에 주목하는 것은 이 때문이다. 이를 V2X(차량 사물 통신 – Vehicle to Everything)이라 부른다.\n",
        "​\n",
        "자율주행 기술은 먼저 컨볼루션 신경망 계열의 학습 알고리즘을 사용하여 카메라 등을 통해 수집된 방대한 이미지 데이터를 컴퓨터가 인식할 수 있는 모델로 변환시킨다. 그리고 빠른 학습을 위해 GPU 및 전용 칩 등을 활용하여 병렬 처리하고, 이렇게 만들어진 모델을 시뮬레이터에서 돌려 강화 학습을 진행한다. 그 후, 실제 환경에서 시험 운전을 거쳐 완전한 자율주행을 달성한다.\n",
        "\n",
        "\n"
      ]
    }
  ]
}